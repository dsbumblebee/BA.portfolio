{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 감성분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. VADER\n",
    "- 2. WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/jin/Documents/pythonstudy/NLP/frip_data_lda/lda_all.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10740 entries, 0 to 10739\n",
      "Data columns (total 15 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   날짜             10740 non-null  object \n",
      " 1   내용             10740 non-null  object \n",
      " 2   별점             10740 non-null  float64\n",
      " 3   제목             10740 non-null  object \n",
      " 4   카테고리           10740 non-null  object \n",
      " 5   지역             10740 non-null  object \n",
      " 6   가격             10740 non-null  int64  \n",
      " 7   review         10740 non-null  object \n",
      " 8   s_review       10740 non-null  object \n",
      " 9   번역             10740 non-null  object \n",
      " 10  t_preprocess   10740 non-null  object \n",
      " 11  clean_word     10740 non-null  object \n",
      " 12  Drop_stopword  10740 non-null  object \n",
      " 13  Topic          10740 non-null  int64  \n",
      " 14  Topic_code     10740 non-null  object \n",
      "dtypes: float64(1), int64(2), object(12)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vader'] = data['번역'].apply(senti_analyzer.polarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['v_neg'] = [vader['neg'] for vader in data['vader']]\n",
    "data['v_pos'] = [vader['pos'] for vader in data['vader']]\n",
    "data['v_neu'] = [vader['neu'] for vader in data['vader']]\n",
    "data['v_com'] = [vader['compound'] for vader in data['vader']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):  # 문자열.statswith('문자1') : 문자열 앞이 문자1로 시작하나?\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swn_polarity(text):\n",
    "    pos_sentiment= 0.0\n",
    "    neg_sentiment= 0.0\n",
    "    tokens_count = 0 \n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    raw_sentences = sent_tokenize(text)\n",
    "    \n",
    "    for raw_sentence in raw_sentences:\n",
    "        tagged_sentence = pos_tag(word_tokenize(raw_sentence))\n",
    "        for word, tag in tagged_sentence:\n",
    "            \n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV, wn.VERB):\n",
    "                continue  # 명사, 형용사, 부사가 아니면 아무것도 안한다.\n",
    "            \n",
    "            # 그렇지 않으면, 원형화 한다. (명사, 형용사, 부사면 원형화 한다.)\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma :  # 공백이면, \n",
    "                continue \n",
    "            # 원형으로 된 단어, tagging\n",
    "            synsets = wn.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets : # 공백이면,\n",
    "                continue\n",
    "            \n",
    "            synset = synsets[0] # 첫번째, 뜻으로 \n",
    "            swn_synset = swn.senti_synset(synset.name()) # name() 태깅된 단어\n",
    "            #sentiment += (swn_synset.pos_score() - swn_synset.neg_score())\n",
    "            \n",
    "            pos = swn_synset.pos_score()\n",
    "            neg = swn_synset.neg_score()\n",
    "            \n",
    "            pos_sentiment += swn_synset.pos_score()\n",
    "            neg_sentiment += swn_synset.neg_score()\n",
    "            \n",
    "            if pos > neg :\n",
    "                pos_count += 1\n",
    "            elif pos == neg:\n",
    "                pass\n",
    "            else : \n",
    "                neg_count += 1\n",
    "            \n",
    "            tokens_count += 1\n",
    "    \n",
    "    if not tokens_count :   # tokens_count 가 0이면\n",
    "        return 0\n",
    "    \n",
    "    return {'pos_sent':pos_sentiment, 'neg_sent':neg_sentiment, 'pos_count':pos_count, 'neg_count':neg_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['wordnet'] = data['번역'].apply(swn_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos_sent': 5.125, 'neg_sent': 1.375, 'pos_count': 13, 'neg_count': 1}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['wordnet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['N_negword'] = [vader['neg_count'] for vader in data['wordnet']]\n",
    "data['N_posword'] = [vader['pos_count'] for vader in data['wordnet']]\n",
    "data['w_possent'] = [vader['pos_sent'] for vader in data['wordnet']]\n",
    "data['w_negsent'] = [vader['neg_sent'] for vader in data['wordnet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(num):\n",
    "    print('1.원문 : ', data['s_review'][num])\n",
    "    print('2.번역 : ', data['번역'][num])\n",
    "    print('3.긍부정단어수 : ', swn_polarity(data['번역'][num]))\n",
    "    print('4.VADER : ',data['vader'][num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.원문 :  6시간 중에 1시간은 맥주의 재료와 종류 등에 대해 간단히 알려주시고 남은 5시간은 정말 딱 맞춰서 맥주를 만들었어요 당화시키고 홉 넣고 끓이고 식히는 중간 중간에 아이홉 공방에서 판매 중인 맥주들에 대해 하나 하나 그 스타일과 간단한 히스토리 등에 대해 알려주시고 자칫 지루할 수 있는 기 다림의 시간을 빙고게임과 함께 하니 후딱 지나갔네요 다음에 도 또 개인적으로 방문하고 싶은 곳입니다\n",
      "2.번역 :  One hour of six hours is a brief reminder of the ingredients and types of beer, and the remaining five hours are really just right, making beer. One by one, tell me about the style and simple history of the beer sold in the I-hop workshop in the middle of saccharification, hop, boiling and cooling.\n",
      "3.긍부정단어수 :  {'pos_sent': 1.25, 'neg_sent': 0.625, 'pos_count': 3, 'neg_count': 1}\n",
      "4.VADER :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "check(6787)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분석결과 \n",
    "\n",
    "- VADER가 Wordnet보다 성능이 우수한 것으로 판단된다. \n",
    "- Wordnet에서 첫번째 단어 뜻을 가져와서 쓰는점이 성능을 저하 시킬 것으로 보인다.\n",
    "- VADER는 집단지성을 기반으로 만들었기 때문에, 단순 긍/부정 단어의 수를 새는 것보다 좋은 성능을 보이는 것으로 생각된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단어수 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review_length'] = data['s_review'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장 \n",
    "data.to_csv('/Users/jin/Documents/pythonstudy/NLP/frip_data_result/frip_data_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
